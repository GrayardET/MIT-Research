{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN5ZLaW9TXeI"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, SpatialDropout1D\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import KFold\n",
        "import re\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWsk5Uj7emTX"
      },
      "source": [
        "# Reading Dataset\n",
        "\n",
        "train = pd.read_csv('Corona_NLP_train.csv', engine='python')\n",
        "test = pd.read_csv('Corona_NLP_test.csv', engine='python')\n",
        "\n",
        "# Pre-processing Dataset\n",
        "\n",
        "train = train[['OriginalTweet','Sentiment']]\n",
        "train = train.rename(columns={'OriginalTweet': 'text'})\n",
        "train = train.rename(columns={'Sentiment': 'sentiment'})\n",
        "\n",
        "test = test[['OriginalTweet','Sentiment']]\n",
        "test = test.rename(columns={'OriginalTweet': 'text'})\n",
        "test = test.rename(columns={'Sentiment': 'sentiment'})\n",
        "\n",
        "for idx,row in train.iterrows():\n",
        "    row[0] = row[0].replace('rt',' ')\n",
        "\n",
        "for idx,row in test.iterrows():\n",
        "    row[0] = row[0].replace('rt',' ')\n",
        "    \n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(train['text'].values)\n",
        "tokenizer.fit_on_texts(test['text'].values)\n",
        "\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(train['text'].values))\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(test['text'].values))\n",
        "\n",
        "y_train = pd.get_dummies(train['sentiment']).values\n",
        "y_test = pd.get_dummies(test['sentiment']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI5YgW-RyX_-"
      },
      "source": [
        "# Setting up LSTM Model\n",
        "embed_dim = 128\n",
        "out_dim = 196\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(max_features, embed_dim, input_length = x_train.shape[1]))\n",
        "lstm_model.add(SpatialDropout1D(0.4))\n",
        "lstm_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "lstm_model.add(Dense(5,activation='sigmoid'))\n",
        "lstm_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "lstm_model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(lstm_model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jumT7HQFzwCi"
      },
      "source": [
        "# Setting up GRU Model\n",
        "embed_dim = 128\n",
        "out_dim = 196\n",
        "\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(max_features, embed_dim, input_length = x_train.shape[1]))\n",
        "gru_model.add(SpatialDropout1D(0.4))\n",
        "gru_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "gru_model.add(Dense(5,activation='sigmoid'))\n",
        "gru_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "gru_model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(gru_model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM8REYvAOmJc"
      },
      "source": [
        "def evaluate_model(model, kfold, lr, epoch, n_embedding, n_hidden, dropout, note = ''):\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        hists = []\n",
        "        train_acc = []\n",
        "        val_acc = []\n",
        "        kf = KFold(kfold, shuffle = True)\n",
        "        \n",
        "        for train, test in kf.split(x_train, y_train):\n",
        "\n",
        "            # Training Model\n",
        "            hist = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "            # Testing Model\n",
        "            test_results = model.evaluate(x_train, y_train, verbose=False)\n",
        "            print(f'Test results - Loss: {test_results[0]} - Accuracy: {100 * test_results[1]}%')\n",
        "            test_acc = test_results[1]\n",
        "\n",
        "            train_acc.append(hist.history['accuracy'])\n",
        "            val_acc.append(hist.history['val_accuracy'])\n",
        "\n",
        "    return train_acc, val_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3V5StbSx2wf"
      },
      "source": [
        "# Parameters\n",
        "kfold = 3\n",
        "lr = 0.0005\n",
        "epoch = 10\n",
        "n_embedding = 50\n",
        "n_hidden = 150\n",
        "dropout = 0.00\n",
        "\n",
        "# K-fold Evaluation of LSTM/GRU Model\n",
        "\n",
        "model = lstm_model # or gru_model\n",
        "train_acc, val_acc = evaluate_model(model, kfold = kfold, lr = lr, epoch = epoch, n_embedding = n_embedding, n_hidden = n_hidden, dropout=dropout)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_Ma7Edd1Zqd"
      },
      "source": [
        "def plotKfold(train_acc, val_acc, title, saveName):\n",
        "    train_acc_list = np.array(train_acc)\n",
        "    eval_acc_list = np.array(val_acc)\n",
        "    eval_mean = np.mean(eval_acc_list, axis = 0)\n",
        "    eval_std = np.std(eval_acc_list, axis = 0)\n",
        "    train_mean = np.mean(train_acc_list, axis = 0)\n",
        "    train_std = np.std(train_acc_list, axis = 0)\n",
        "\n",
        "    k_list = range(1,6)\n",
        "\n",
        "    plt.plot(k_list, train_mean, label='Train', linewidth = 2)\n",
        "    plt.errorbar(k_list, eval_mean, eval_std, label='Validation', linewidth = 2)\n",
        "\n",
        "    plt.xticks(range(0,5, 1))\n",
        "    plt.legend()\n",
        "    plt.xlabel('Number of Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.savefig(f'{saveName}.jpg', format = 'JPEG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SXVx853gWQy"
      },
      "source": [
        "plotKfold(train_acc, val_acc, '3-Fold Covid Tweets', \n",
        "          '3-Fold Covid Tweets')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
